# Glenn Easter  
**Cybersecurity Professional | Emerging Security & AI Systems Leader**

---

## Executive Profile

I am a cybersecurity practitioner in development focused on defensive security operations, detection engineering, and responsible automation governance.

Currently completing the Merit America Cybersecurity Program, I am strengthening practical capability in incident response, vulnerability analysis, network fundamentals, and SQL-based telemetry investigation. My approach centers on disciplined interpretation — understanding not just what tools report, but what findings mean, why they matter, and how they should be addressed.

As automation and AI increasingly scale security workflows, preserving structured human judgment becomes critical. My work emphasizes governance, contextual risk assessment, and guardrails that ensure automation supports — rather than replaces — accountable decision-making.

All experimentation is conducted in isolated, authorized lab environments.

---

## Core Technical Domains

**Security Operations & Incident Response**
- Incident lifecycle modeling (NIST / SANS)
- Log correlation and anomaly identification
- Vulnerability triage and remediation prioritization
- Post-incident analysis and documentation

**Detection Engineering & Data Analysis**
- SQL-driven log analysis and threshold tuning
- Time-window aggregation strategies
- Threat hypothesis translation into measurable queries
- Context-aware false positive reduction

**Networking & Systems**
- TCP/IP protocol analysis
- Port and service interpretation
- Linux command-line investigative workflows
- Defensive scanning in controlled lab environments

**Responsible Automation**
- Human-in-the-loop validation
- Scope enforcement and authorization controls
- Non-destructive defaults
- Risk contextualization before escalation

---

## Independent Research & Applied Practice

### Project G.I.R. (Glitch, Intrude, Repeat)

Project G.I.R. is a disciplined interpretation framework designed to teach structured vulnerability analysis within a controlled lab environment.

Its emphasis is not exploitation, but judgment training. The framework:

- Converts raw scan output into contextual risk reasoning  
- Requires human review before escalation  
- Enforces strict scope boundaries  
- Prioritizes remediation-focused thinking  

As AI-assisted security tooling evolves, this project explores how automation can remain aligned with ethical oversight and decision accountability.

---

## Security & AI Philosophy

Automation increases speed. AI increases scale. Without governance, both increase risk.

I am particularly interested in designing defensive systems where:

- Reasoning paths remain transparent  
- Authorization boundaries are explicit  
- Validation checkpoints are mandatory  
- Risk is interpreted in operational context  

The future of security depends not only on smarter tools, but on structured frameworks that preserve accountability.

---

## Professional Direction

**Short-Term**
- Contribute to a security operations team in a SOC or analyst capacity  
- Strengthen investigative reasoning and detection workflows  

**Long-Term**
- Contribute to responsible AI integration in defensive security operations  
- Develop expertise in detection architecture and incident response strategy  
- Help shape governance standards for scalable security automation  

---

*This portfolio documents structured growth from student to practitioner. All work is conducted in authorized lab environments for defensive and educational purposes.*
